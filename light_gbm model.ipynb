{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5cbf36",
   "metadata": {},
   "source": [
    "# Light GBM model\n",
    "In this notebook, we will create a simple Light LGM model and evaluate it's accuracy\n",
    "\n",
    "First, let's import the libs and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad209d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844787a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_data.csv\", sep=\";\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df = df.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c5d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_index = list(df[\"country\"].unique())\n",
    "platform_index = list(df[\"creation_platform\"].unique())\n",
    "source_index = list(df[\"source_pulido\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da60f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_values = df.drop([\"country\", \"creation_platform\", \"source_pulido\"], axis=1)\n",
    "df_num_values[\"country_index\"] = df[\"country\"].apply(lambda i: country_index.index(i))\n",
    "df_num_values[\"creation_platform_index\"] = df[\"creation_platform\"].apply(lambda i: platform_index.index(i))\n",
    "df_num_values[\"source_pulido_index\"] = df[\"source_pulido\"].apply(lambda i: source_index.index(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a8985",
   "metadata": {},
   "source": [
    "Now we are going to split the data into train and test datasets and load them into lightgbm datasets.\n",
    "\n",
    "The separation will be:\n",
    " - 80% for training\n",
    " - 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c931a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_num_values.drop(\"target\", axis=1), df_num_values.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48c532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa9729",
   "metadata": {},
   "source": [
    "Now we are going to define the training parameters: [Check the documentation](https://lightgbm.readthedocs.io/en/latest/Parameters.html)\n",
    "\n",
    "- The objetive will be a binary classification, with a `binary_error` metric.\n",
    "- For boosting type, we'll use traditional Gradient Boosting Decision Tree, `gbdt`\n",
    "- The number of leaves will be `31` \n",
    "- Our learning rate will be `0.05`\n",
    "- And will define some others parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4acce342",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16317af",
   "metadata": {},
   "source": [
    "Now, we will train the model for `100` rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b278231",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f19d3a",
   "metadata": {},
   "source": [
    "After training, it's time to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f7c6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda28434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9229336795708477\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c440fdff",
   "metadata": {},
   "source": [
    "The accuracy seems pretty high. But because our data is imbalanced, let's check the accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3a7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_0_preds = y_pred[y_test == 0] <= 0.5\n",
    "target_1_preds = y_pred[y_test == 1] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3a40557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True] [   691 107057]\n",
      "Accuracy for negative targets: 0.9935868879236738\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(target_0_preds, return_counts=True)\n",
    "print(unique, counts)\n",
    "print(\"Accuracy for negative targets:\", counts[1]/counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d93c47ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True] [8331  989]\n",
      "Accuracy for positive targets: 0.10611587982832618\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(target_1_preds, return_counts=True)\n",
    "print(unique, counts)\n",
    "print(\"Accuracy for positive targets:\", counts[1]/counts.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b6816",
   "metadata": {},
   "source": [
    "The accuracy for positiva targets was really high. But for negative targets, it was awful.\n",
    "\n",
    "Maybe we can fix this by creating a threshold for the classification\n",
    "\n",
    "So, let's print the percentiles for each possible target, 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9523e87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0016176 , 0.0054814 , 0.0162957 , 0.05472345, 0.78071773])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(y_pred[y_test == 0], [0, 30, 50, 70, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46a5dabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0016337 , 0.15414669, 0.25907854, 0.37273034, 0.77300839])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(y_pred[y_test == 1], [0, 30, 50, 70, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd2f613",
   "metadata": {},
   "source": [
    "Now we know that 70% of the negative targets have the value up to 0.05\n",
    "\n",
    "We can try some thresholds around this value to find a good accuracy for both targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cf57be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_0_preds = y_pred[y_test == 0] <= 0.1\n",
    "target_1_preds = y_pred[y_test == 1] > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae5326fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True] [21440 86308]\n",
      "Accuracy for negative targets: 0.8010171882540743\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(target_0_preds, return_counts=True)\n",
    "print(unique, counts)\n",
    "print(\"Accuracy for negative targets:\", counts[1]/counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b2c453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True] [1837 7483]\n",
      "Accuracy for positive targets: 0.8028969957081545\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(target_1_preds, return_counts=True)\n",
    "print(unique, counts)\n",
    "print(\"Accuracy for positive targets:\", counts[1]/counts.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca36ccc",
   "metadata": {},
   "source": [
    "Great! With our new threshold we were able to increase our accuracy to 0.8 in both targets.\n",
    "\n",
    "Let's save this model as a pickle so we can use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "885f0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('models/lightgbm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(bst, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad908e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
